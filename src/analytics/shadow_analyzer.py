"""å½±å­äº¤æ˜“åˆ†æå™¨

å®æ—¶ç›‘æ§å’Œåˆ†æå½±å­äº¤æ˜“çš„æ‰€æœ‰å…³é”®æŒ‡æ ‡ã€‚
ç”¨äºéªŒè¯ç­–ç•¥æ˜¯å¦æ»¡è¶³ä¸Šçº¿æ ‡å‡†ã€‚
"""

import time
from collections import deque
from dataclasses import dataclass
from decimal import Decimal

import numpy as np
import structlog
from scipy import stats

from src.core.types import SignalScore
from src.execution.shadow_executor import ShadowExecutionRecord
from src.risk.shadow_position_manager import ShadowPositionManager

logger = structlog.get_logger()


@dataclass
class SignalQualityMetrics:
    """ä¿¡å·è´¨é‡æŒ‡æ ‡"""

    ic: float  # Information Coefficient (Spearman)
    ic_p_value: float  # IC æ˜¾è‘—æ€§ p å€¼
    top_quintile_return: float  # Top 20% å¹³å‡æ”¶ç›Š
    bottom_quintile_return: float  # Bottom 20% å¹³å‡æ”¶ç›Š
    signal_std: float  # ä¿¡å·æ ‡å‡†å·®
    signal_mean: float  # ä¿¡å·å‡å€¼
    sample_size: int  # æ ·æœ¬æ•°é‡


@dataclass
class ExecutionEfficiencyMetrics:
    """æ‰§è¡Œæ•ˆç‡æŒ‡æ ‡"""

    avg_signal_latency_ms: float  # å¹³å‡ä¿¡å·å»¶è¿Ÿ
    avg_decision_latency_ms: float  # å¹³å‡å†³ç­–å»¶è¿Ÿ
    avg_total_latency_ms: float  # å¹³å‡æ€»å»¶è¿Ÿ
    p99_total_latency_ms: float  # p99 æ€»å»¶è¿Ÿ
    fill_rate: float  # æˆäº¤ç‡ (%)
    partial_fill_rate: float  # éƒ¨åˆ†æˆäº¤ç‡ (%)
    avg_slippage_bps: float  # å¹³å‡æ»‘ç‚¹ï¼ˆåŸºç‚¹ï¼‰
    p99_slippage_bps: float  # p99 æ»‘ç‚¹ï¼ˆåŸºç‚¹ï¼‰
    sample_count: int = 0  # æ ·æœ¬æ•°é‡ï¼ˆç”¨äºå»¶è¿Ÿå‘Šè­¦é˜ˆå€¼æ£€æŸ¥ï¼‰


@dataclass
class RiskMetrics:
    """é£æ§æŒ‡æ ‡"""

    max_drawdown: Decimal  # æœ€å¤§å›æ’¤
    max_drawdown_pct: float  # æœ€å¤§å›æ’¤ç™¾åˆ†æ¯”
    max_single_loss: Decimal  # æœ€å¤§å•ç¬”äºæŸ
    consecutive_losses: int  # æœ€å¤§è¿ç»­äºæŸæ¬¡æ•°
    current_drawdown: Decimal  # å½“å‰å›æ’¤
    peak_nav: Decimal  # å†å²æœ€é«˜ NAV
    sharpe_ratio: float  # å¤æ™®æ¯”ç‡ï¼ˆå¹´åŒ–ï¼‰  # å†å²æœ€é«˜ NAV


@dataclass
class PnLAttribution:
    """PnL å½’å› """

    total_pnl: Decimal
    alpha: Decimal  # æ–¹å‘æ€§æ”¶ç›Š
    fee: Decimal  # æ‰‹ç»­è´¹
    slippage: Decimal  # æ»‘ç‚¹
    alpha_percentage: float  # Alpha å æ¯” (%)
    cost_percentage: float  # æˆæœ¬å æ¯” (%)
    num_trades: int
    win_rate: float | None  # èƒœç‡ (%)ï¼Œæš‚æ—¶ç¦ç”¨ï¼ˆéœ€è¦å®Œæ•´æŒä»“è¿½è¸ªç³»ç»Ÿï¼‰


@dataclass
class ShadowTradingReport:
    """å½±å­äº¤æ˜“ç»¼åˆæŠ¥å‘Š"""

    signal_quality: SignalQualityMetrics
    execution_efficiency: ExecutionEfficiencyMetrics
    risk_metrics: RiskMetrics
    pnl_attribution: PnLAttribution
    runtime_hours: float
    system_uptime_pct: float
    ready_for_launch: bool  # æ”¹åï¼šmeets_launch_criteria â†’ ready_for_launch
    launch_score: float  # æ”¹åï¼šlaunch_readiness_score â†’ launch_score  # 0-100
    criteria_details: dict[str, dict[str, float]]  # è¯¦ç»†çš„æ ‡å‡†æ£€æŸ¥ç»“æœ


class ShadowAnalyzer:
    """å½±å­äº¤æ˜“åˆ†æå™¨

    èŒè´£ï¼š
        1. å®æ—¶æ”¶é›†å’Œåˆ†ææ‰€æœ‰æ‰§è¡Œè®°å½•
        2. è®¡ç®—ä¿¡å·è´¨é‡æŒ‡æ ‡ï¼ˆICã€åˆ†å±‚æ”¶ç›Šï¼‰
        3. è®¡ç®—æ‰§è¡Œæ•ˆç‡æŒ‡æ ‡ï¼ˆå»¶è¿Ÿã€æˆäº¤ç‡ã€æ»‘ç‚¹ï¼‰
        4. è®¡ç®—é£æ§æŒ‡æ ‡ï¼ˆå›æ’¤ã€è¿ç»­äºæŸï¼‰
        5. è¿›è¡Œ PnL å½’å› åˆ†æ
        6. ç”Ÿæˆç»¼åˆæŠ¥å‘Šå¹¶åˆ¤æ–­æ˜¯å¦æ»¡è¶³ä¸Šçº¿æ ‡å‡†
    """

    def __init__(
        self,
        position_manager: ShadowPositionManager,
        initial_nav: Decimal,
        ic_window_hours: int = 1,
        launch_criteria: dict[str, float] | None = None,
    ):
        """
        åˆå§‹åŒ–å½±å­äº¤æ˜“åˆ†æå™¨

        Args:
            position_manager: å½±å­æŒä»“ç®¡ç†å™¨
            initial_nav: åˆå§‹å‡€å€¼
            ic_window_hours: IC è®¡ç®—çª—å£ï¼ˆå°æ—¶ï¼‰
            launch_criteria: ä¸Šçº¿æ ‡å‡†
        """
        self.position_manager = position_manager
        self.initial_nav = initial_nav
        self.ic_window_hours = ic_window_hours

        # é»˜è®¤ä¸Šçº¿æ ‡å‡†
        self.launch_criteria = launch_criteria or {
            "ic_min": 0.03,
            "alpha_pct_min": 70.0,
            "cost_pct_max": 25.0,
            "uptime_pct_min": 99.9,
            "p99_latency_ms_max": 150.0,
        }

        # æ•°æ®æ”¶é›†
        self._execution_records: list[ShadowExecutionRecord] = []
        # ä¸é™åˆ¶ deque é•¿åº¦ï¼Œä½¿ç”¨æ—¶é—´çª—å£è¿‡æ»¤ï¼ˆé¿å…æ—©æœŸä¿¡å·è¢«æŒ¤å‡ºï¼‰
        self._signal_history: deque = deque()

        # æ€§èƒ½æŒ‡æ ‡
        self._peak_nav = initial_nav
        self._max_drawdown = Decimal("0")
        self._max_single_loss = Decimal("0")
        self._consecutive_losses = 0
        self._current_consecutive_losses = 0

        # ç³»ç»Ÿç›‘æ§
        self._start_time = time.time()
        self._total_downtime_seconds = 0.0
        
        # NAV å†å²ï¼ˆç”¨äºè®¡ç®—å¤æ™®æ¯”ç‡ï¼‰
        self._nav_history: list[tuple[float, Decimal]] = []  # [(timestamp, nav), ...]

        # ä¿¡å· ID è®¡æ•°å™¨ï¼ˆç”¨äºæœªæ¥æ”¶ç›Šè·Ÿè¸ªï¼‰
        self._next_signal_id = 0

        logger.info(
            "shadow_analyzer_initialized",
            initial_nav=float(initial_nav),
            ic_window_hours=ic_window_hours,
            launch_criteria=self.launch_criteria,
        )

    def record_execution(self, record: ShadowExecutionRecord) -> None:
        """
        è®°å½•æ‰§è¡Œè®°å½•

        Args:
            record: å½±å­æ‰§è¡Œè®°å½•
        """
        self._execution_records.append(record)
        
        # è®°å½• NAV å†å²ï¼ˆç”¨äºå¤æ™®æ¯”ç‡è®¡ç®—ï¼‰
        current_nav = self.initial_nav + self.position_manager.get_total_pnl()
        self._nav_history.append((time.time(), current_nav))

        # æ›´æ–°é£æ§æŒ‡æ ‡
        if record.execution_result and not record.skipped:
            # è®¡ç®—ç›ˆäº
            pnl = self._calculate_trade_pnl(record)

            # æ›´æ–°è¿ç»­äºæŸ
            if pnl < 0:
                self._current_consecutive_losses += 1
                self._consecutive_losses = max(
                    self._consecutive_losses, self._current_consecutive_losses
                )

                # æ›´æ–°æœ€å¤§å•ç¬”äºæŸ
                if pnl < self._max_single_loss:
                    self._max_single_loss = pnl
            else:
                self._current_consecutive_losses = 0

        logger.debug(
            "execution_recorded",
            order_id=record.order.id,
            skipped=record.skipped,
            filled=record.execution_result is not None,
        )

    def record_signal(self, signal: SignalScore, future_return: float | None = None) -> int:
        """
        è®°å½•ä¿¡å·ï¼ˆç”¨äº IC è®¡ç®—ï¼‰

        Args:
            signal: ä¿¡å·è¯„åˆ†
            future_return: æœªæ¥æ”¶ç›Šï¼ˆT+n æ”¶ç›Šç‡ï¼Œç”¨äºè®¡ç®— ICï¼‰

        Returns:
            int: ä¿¡å·å”¯ä¸€æ ‡è¯†ï¼ˆç”¨äºåç»­æ›´æ–°ï¼‰
        """
        signal_id = self._next_signal_id
        self._next_signal_id += 1

        # å°†æ¯«ç§’æ—¶é—´æˆ³è½¬æ¢ä¸ºç§’ï¼ˆä¸ time.time() å•ä½ç»Ÿä¸€ï¼‰
        timestamp_sec = signal.timestamp / 1000.0

        self._signal_history.append({
            "id": signal_id,
            "timestamp": timestamp_sec,  # å­˜å‚¨ç§’çº§æ—¶é—´æˆ³
            "signal_value": signal.value,
            "future_return": future_return,
        })

        return signal_id

    def update_signal_future_return(self, signal_id: int, future_return: float) -> None:
        """
        æ›´æ–°ä¿¡å·çš„æœªæ¥æ”¶ç›Š

        ç”± FutureReturnTracker åœ¨ T+n æ—¶åˆ»è°ƒç”¨ã€‚

        Args:
            signal_id: ä¿¡å·å”¯ä¸€æ ‡è¯†
            future_return: æœªæ¥æ”¶ç›Šç‡
        """
        # æŸ¥æ‰¾å¹¶æ›´æ–°ä¿¡å·
        for signal in self._signal_history:
            if signal.get("id") == signal_id:
                signal["future_return"] = future_return
                logger.debug(
                    "signal_future_return_updated",
                    signal_id=signal_id,
                    future_return=future_return,
                )
                return

        # å¦‚æœæ‰¾ä¸åˆ°ä¿¡å·ï¼Œè®°å½•è­¦å‘Š
        logger.warning(
            "signal_not_found_for_update",
            signal_id=signal_id,
        )

    def calculate_signal_quality(self) -> SignalQualityMetrics:
        """
        è®¡ç®—ä¿¡å·è´¨é‡æŒ‡æ ‡

        Returns:
            SignalQualityMetrics: ä¿¡å·è´¨é‡æŒ‡æ ‡
        """
        # è®¡ç®—æ—¶é—´çª—å£ï¼ˆåªç»Ÿè®¡çª—å£å†…çš„ä¿¡å·ï¼‰
        cutoff_time = time.time() - (self.ic_window_hours * 3600)

        # è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºè¿‡æ»¤å‰çš„çŠ¶æ€
        logger.info(
            "signal_quality_calculation_start",
            total_signals=len(self._signal_history),
            cutoff_time=cutoff_time,
            ic_window_hours=self.ic_window_hours,
            sample_timestamps=[
                s.get("timestamp") for s in list(self._signal_history)[:3]
            ] if self._signal_history else [],
        )

        # è¿‡æ»¤ï¼šåœ¨æ—¶é—´çª—å£å†… AND æœ‰æœªæ¥æ”¶ç›Š
        valid_signals = [
            s for s in self._signal_history
            if s.get("timestamp", 0) >= cutoff_time
            and s.get("future_return") is not None
        ]

        # è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºè¿‡æ»¤ç»“æœ
        logger.info(
            "signal_quality_filtered",
            valid_count=len(valid_signals),
            with_future_return=sum(1 for s in self._signal_history if s.get("future_return") is not None),
            in_time_window=sum(1 for s in self._signal_history if s.get("timestamp", 0) >= cutoff_time),
        )

        if len(valid_signals) < 30:
            logger.warning(
                "insufficient_signals_for_ic",
                count=len(valid_signals),
                min_required=30,
            )
            return SignalQualityMetrics(
                ic=0.0,
                ic_p_value=1.0,
                top_quintile_return=0.0,
                bottom_quintile_return=0.0,
                signal_std=0.0,
                signal_mean=0.0,
                sample_size=len(valid_signals),
            )

        signals = np.array([s["signal_value"] for s in valid_signals])
        returns = np.array([s["future_return"] for s in valid_signals])

        # ========== ğŸ” è¯Šæ–­æ—¥å¿— START ==========
        # è¾“å‡ºå‰ 20 ä¸ªæ ·æœ¬ç”¨äºè¯Šæ–­
        sample_size = min(20, len(valid_signals))
        logger.info(
            "ic_diagnosis_samples",
            sample_count=sample_size,
            samples=[
                {
                    "signal": float(signals[i]),
                    "return": float(returns[i] * 100),  # è½¬ä¸ºç™¾åˆ†æ¯”
                    "timestamp": valid_signals[i].get("timestamp"),
                }
                for i in range(sample_size)
            ],
        )

        # ç»Ÿè®¡ä¿¡æ¯
        logger.info(
            "ic_diagnosis_stats",
            signal_mean=float(np.mean(signals)),
            signal_std=float(np.std(signals)),
            signal_min=float(np.min(signals)),
            signal_max=float(np.max(signals)),
            return_mean_pct=float(np.mean(returns) * 100),
            return_std_pct=float(np.std(returns) * 100),
            return_min_pct=float(np.min(returns) * 100),
            return_max_pct=float(np.max(returns) * 100),
            positive_signal_count=int(np.sum(signals > 0)),
            negative_signal_count=int(np.sum(signals < 0)),
            positive_return_count=int(np.sum(returns > 0)),
            negative_return_count=int(np.sum(returns < 0)),
        )
        # ========== ğŸ” è¯Šæ–­æ—¥å¿— END ==========

        # è®¡ç®— IC (Spearman ç›¸å…³ç³»æ•°)
        ic, p_value = stats.spearmanr(signals, returns)

        # åˆ†å±‚æ”¶ç›Šï¼ˆTop 20% vs Bottom 20%)
        sorted_indices = np.argsort(signals)
        quintile_size = max(1, len(signals) // 5)  # ç¡®ä¿è‡³å°‘æœ‰ 1 ä¸ªæ ·æœ¬

        if quintile_size > 0 and len(signals) >= 5:
            top_quintile_return = float(np.mean(returns[sorted_indices[-quintile_size:]]))
            bottom_quintile_return = float(
                np.mean(returns[sorted_indices[:quintile_size]])
            )
        else:
            # æ ·æœ¬æ•°é‡ä¸è¶³ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®çš„å¹³å‡å€¼
            logger.warning(
                "insufficient_signals_for_quintile",
                count=len(signals),
                min_required=5,
            )
            top_quintile_return = float(np.mean(returns))
            bottom_quintile_return = float(np.mean(returns))

        return SignalQualityMetrics(
            ic=float(ic),
            ic_p_value=float(p_value),
            top_quintile_return=top_quintile_return,
            bottom_quintile_return=bottom_quintile_return,
            signal_std=float(np.std(signals)),
            signal_mean=float(np.mean(signals)),
            sample_size=len(valid_signals),
        )

    def calculate_execution_efficiency(self) -> ExecutionEfficiencyMetrics:
        """
        è®¡ç®—æ‰§è¡Œæ•ˆç‡æŒ‡æ ‡

        Returns:
            ExecutionEfficiencyMetrics: æ‰§è¡Œæ•ˆç‡æŒ‡æ ‡
        """
        if not self._execution_records:
            return ExecutionEfficiencyMetrics(
                avg_signal_latency_ms=0.0,
                avg_decision_latency_ms=0.0,
                avg_total_latency_ms=0.0,
                p99_total_latency_ms=0.0,
                fill_rate=0.0,
                partial_fill_rate=0.0,
                avg_slippage_bps=0.0,
                p99_slippage_bps=0.0,
                sample_count=0,
            )

        # å»¶è¿Ÿç»Ÿè®¡
        total_latencies = [r.total_latency_ms for r in self._execution_records]
        signal_latencies = [r.signal_latency_ms for r in self._execution_records]
        decision_latencies = [r.decision_latency_ms for r in self._execution_records]

        # æˆäº¤ç»Ÿè®¡
        filled_records = [
            r for r in self._execution_records if r.fill_result is not None
        ]
        partial_fills = [
            r for r in filled_records if r.fill_result.partial_fill
        ]

        total_orders = len([r for r in self._execution_records if not r.skipped])
        fill_rate = (
            (len(filled_records) / total_orders * 100) if total_orders > 0 else 0.0
        )
        partial_fill_rate = (
            (len(partial_fills) / len(filled_records) * 100)
            if filled_records
            else 0.0
        )

        # æ»‘ç‚¹ç»Ÿè®¡
        slippages = [
            r.fill_result.slippage_bps
            for r in filled_records
            if r.fill_result
        ]

        # è®¡ç®—å»¶è¿Ÿåˆ†ä½æ•°ï¼ˆå…ˆæ£€æŸ¥æ˜¯å¦ä¸ºç©ºï¼‰
        p99_latency = (
            float(np.percentile(total_latencies, 99))
            if total_latencies and len(total_latencies) >= 2
            else 0.0
        )

        # è®¡ç®—æ»‘ç‚¹åˆ†ä½æ•°ï¼ˆå…ˆæ£€æŸ¥æ˜¯å¦ä¸ºç©ºï¼‰
        p99_slip = (
            float(np.percentile(slippages, 99))
            if slippages and len(slippages) >= 2
            else 0.0
        )

        return ExecutionEfficiencyMetrics(
            avg_signal_latency_ms=float(np.mean(signal_latencies))
            if signal_latencies
            else 0.0,
            avg_decision_latency_ms=float(np.mean(decision_latencies))
            if decision_latencies
            else 0.0,
            avg_total_latency_ms=float(np.mean(total_latencies)) if total_latencies else 0.0,
            p99_total_latency_ms=p99_latency,
            fill_rate=fill_rate,
            partial_fill_rate=partial_fill_rate,
            avg_slippage_bps=float(np.mean(slippages)) if slippages else 0.0,
            p99_slippage_bps=p99_slip,
            sample_count=len(total_latencies),  # è®°å½•æ ·æœ¬æ•°é‡
        )

    def calculate_risk_metrics(self) -> RiskMetrics:
        """
        è®¡ç®—é£æ§æŒ‡æ ‡

        Returns:
            RiskMetrics: é£æ§æŒ‡æ ‡
        """
        current_nav = self.initial_nav + self.position_manager.get_total_pnl()

        # æ›´æ–°å³°å€¼
        if current_nav > self._peak_nav:
            self._peak_nav = current_nav

        # å½“å‰å›æ’¤
        current_drawdown = self._peak_nav - current_nav

        # æœ€å¤§å›æ’¤
        if current_drawdown > self._max_drawdown:
            self._max_drawdown = current_drawdown

        max_drawdown_pct = (
            float(self._max_drawdown / self._peak_nav * Decimal("100"))
            if self._peak_nav > 0
            else 0.0
        )

        # è®¡ç®—å¤æ™®æ¯”ç‡
        sharpe_ratio = self._calculate_sharpe_ratio()
        
        return RiskMetrics(
            max_drawdown=self._max_drawdown,
            max_drawdown_pct=max_drawdown_pct,
            max_single_loss=self._max_single_loss,
            consecutive_losses=self._consecutive_losses,
            current_drawdown=current_drawdown,
            peak_nav=self._peak_nav,
            sharpe_ratio=sharpe_ratio,
        )

    def _calculate_sharpe_ratio(self) -> float:
        """è®¡ç®—å¹´åŒ–å¤æ™®æ¯”ç‡
        
        å¤æ™®æ¯”ç‡ = (å¹³å‡æ”¶ç›Šç‡ - æ— é£é™©åˆ©ç‡) / æ”¶ç›Šç‡æ ‡å‡†å·® Ã— âˆš(å¹´åŒ–å› å­)
        
        Returns:
            å¹´åŒ–å¤æ™®æ¯”ç‡ï¼Œæ— è¶³å¤Ÿæ•°æ®æ—¶è¿”å› 0.0
        """
        if len(self._nav_history) < 2:
            return 0.0
        
        # è®¡ç®—æ”¶ç›Šç‡åºåˆ—
        returns = []
        for i in range(1, len(self._nav_history)):
            prev_nav = self._nav_history[i-1][1]
            curr_nav = self._nav_history[i][1]
            
            if prev_nav > 0:
                ret = float((curr_nav - prev_nav) / prev_nav)
                returns.append(ret)
        
        if not returns:
            return 0.0
        
        # è®¡ç®—ç»Ÿè®¡é‡
        mean_return = float(np.mean(returns))
        std_return = float(np.std(returns))
        
        if std_return == 0:
            return 0.0
        
        # å¹´åŒ–å› å­
        # å‡è®¾æ¯æ¬¡æ‰§è¡Œé—´éš”çº¦ 100msï¼ˆé«˜é¢‘äº¤æ˜“ï¼‰
        # æ¯å¤©äº¤æ˜“ 8 å°æ—¶ = 8 * 3600 = 28800 ç§’
        # æ¯ç§’çº¦ 10 æ¬¡æ‰§è¡Œ = æ¯å¤© 288000 æ¬¡
        # ä¸€å¹´ 252 ä¸ªäº¤æ˜“æ—¥
        executions_per_day = 8 * 3600 * 10
        annualization_factor = np.sqrt(executions_per_day * 252)
        
        # æ— é£é™©åˆ©ç‡å‡è®¾ä¸º 0ï¼ˆåŠ å¯†è´§å¸ï¼‰
        sharpe = mean_return / std_return * annualization_factor
        
        return float(sharpe)

    def calculate_pnl_attribution(self) -> PnLAttribution:
        """
        è®¡ç®— PnL å½’å› 

        Returns:
            PnLAttribution: PnL å½’å› 
        """
        total_pnl = self.position_manager.get_total_pnl()

        # ç»Ÿè®¡è´¹ç”¨å’Œæ»‘ç‚¹
        fee_total = Decimal("0")
        slippage_total = Decimal("0")
        num_trades = 0
        # wins = 0  # æš‚æ—¶ç¦ç”¨èƒœç‡ç»Ÿè®¡ï¼ˆéœ€è¦å®Œæ•´æŒä»“è¿½è¸ªç³»ç»Ÿï¼‰

        for record in self._execution_records:
            if record.execution_result and not record.skipped:
                num_trades += 1

                # æ‰‹ç»­è´¹ï¼ˆTaker è´¹ç‡ 5 bpsï¼Œè´Ÿæ•°è¡¨ç¤ºæˆæœ¬ï¼‰
                fill_value = (
                    record.fill_result.filled_size * record.fill_result.avg_fill_price
                )
                fee_total -= fill_value * Decimal("0.0005")

                # æ»‘ç‚¹ï¼ˆè´Ÿæ•°è¡¨ç¤ºæˆæœ¬ï¼‰
                slippage_total -= abs(record.fill_result.slippage) * record.fill_result.filled_size

                # èƒœç‡ç»Ÿè®¡ - æš‚æ—¶ç¦ç”¨ï¼ˆå½“å‰å®ç°ä¸æ­£ç¡®ï¼Œéœ€è¦å®Œæ•´æŒä»“è¿½è¸ªï¼‰
                # pnl = self._calculate_trade_pnl(record)
                # if pnl > 0:
                #     wins += 1

        # Alpha = Total PnL - Fee - Slippage
        # (å› ä¸º fee_total å’Œ slippage_total å·²ç»æ˜¯è´Ÿæ•°ï¼Œæ‰€ä»¥ç”¨å‡æ³•)
        alpha = total_pnl - fee_total - slippage_total

        # è®¡ç®—å æ¯”ï¼ˆä½¿ç”¨ç»å¯¹å€¼ç¡®ä¿è¯­ä¹‰æ¸…æ™°ï¼‰
        if total_pnl != 0:
            base = abs(total_pnl)
            alpha_pct = float(alpha / base * Decimal("100"))
            cost_pct = float((fee_total + slippage_total) / base * Decimal("100"))
        else:
            alpha_pct = 0.0
            cost_pct = 0.0

        # win_rate = (wins / num_trades * 100) if num_trades > 0 else 0.0
        win_rate = None  # æš‚æ—¶ç¦ç”¨ï¼Œéœ€è¦å®Œæ•´æŒä»“è¿½è¸ªç³»ç»Ÿ

        return PnLAttribution(
            total_pnl=total_pnl,
            alpha=alpha,
            fee=fee_total,
            slippage=slippage_total,
            alpha_percentage=alpha_pct,
            cost_percentage=cost_pct,
            num_trades=num_trades,
            win_rate=win_rate,
        )

    def generate_report(self) -> ShadowTradingReport:
        """
        ç”Ÿæˆç»¼åˆæŠ¥å‘Š

        Returns:
            ShadowTradingReport: ç»¼åˆæŠ¥å‘Š
        """
        signal_quality = self.calculate_signal_quality()
        execution_efficiency = self.calculate_execution_efficiency()
        risk_metrics = self.calculate_risk_metrics()
        pnl_attribution = self.calculate_pnl_attribution()

        # è®¡ç®—è¿è¡Œæ—¶é—´
        runtime_hours = (time.time() - self._start_time) / 3600
        total_time = time.time() - self._start_time
        uptime_pct = (
            ((total_time - self._total_downtime_seconds) / total_time * 100)
            if total_time > 0
            else 0.0
        )

        # åˆ¤æ–­æ˜¯å¦æ»¡è¶³ä¸Šçº¿æ ‡å‡†
        meets_criteria, criteria_details = self._check_launch_criteria(
            signal_quality, execution_efficiency, risk_metrics, pnl_attribution, uptime_pct
        )

        # è®¡ç®—å‡†å¤‡åº¦è¯„åˆ†
        readiness_score = self._calculate_readiness_score(
            signal_quality, execution_efficiency, pnl_attribution, uptime_pct
        )

        return ShadowTradingReport(
            signal_quality=signal_quality,
            execution_efficiency=execution_efficiency,
            risk_metrics=risk_metrics,
            pnl_attribution=pnl_attribution,
            runtime_hours=runtime_hours,
            system_uptime_pct=uptime_pct,
            ready_for_launch=meets_criteria,
            launch_score=readiness_score,
            criteria_details=criteria_details,
        )

    def _calculate_trade_pnl(self, record: ShadowExecutionRecord) -> Decimal:
        """è®¡ç®—å•ç¬”äº¤æ˜“ç›ˆäºï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        if not record.execution_result:
            return Decimal("0")

        # è¿™é‡Œç®€åŒ–ä¸ºæ»‘ç‚¹é€ æˆçš„æŸå¤±
        # å®é™…ç›ˆäºéœ€è¦ç­‰å¾…å¹³ä»“æ‰èƒ½ç¡®å®š
        return -abs(record.execution_result.slippage) * record.execution_result.fill_size

    def _check_launch_criteria(
        self,
        signal_quality: SignalQualityMetrics,
        execution_efficiency: ExecutionEfficiencyMetrics,
        risk_metrics: RiskMetrics,
        pnl_attribution: PnLAttribution,
        uptime_pct: float,
    ) -> tuple[bool, dict[str, dict[str, float]]]:
        """æ£€æŸ¥æ˜¯å¦æ»¡è¶³ä¸Šçº¿æ ‡å‡†ï¼Œè¿”å›è¯¦ç»†ä¿¡æ¯"""
        criteria_details = {
            "ic": {
                "actual": signal_quality.ic,
                "required": self.launch_criteria["ic_min"],
                "passed": signal_quality.ic >= self.launch_criteria["ic_min"],
            },
            "alpha_pct": {
                "actual": pnl_attribution.alpha_percentage,
                "required": self.launch_criteria["alpha_pct_min"],
                "passed": pnl_attribution.alpha_percentage
                >= self.launch_criteria["alpha_pct_min"],
            },
            "cost_pct": {
                "actual": pnl_attribution.cost_percentage,
                "required": self.launch_criteria["cost_pct_max"],
                "passed": pnl_attribution.cost_percentage
                <= self.launch_criteria["cost_pct_max"],
            },
            "uptime": {
                "actual": uptime_pct,
                "required": self.launch_criteria["uptime_pct_min"],
                "passed": uptime_pct >= self.launch_criteria["uptime_pct_min"],
            },
            "latency": {
                "actual": execution_efficiency.p99_total_latency_ms,
                "required": self.launch_criteria["p99_latency_ms_max"],
                "passed": execution_efficiency.p99_total_latency_ms
                <= self.launch_criteria["p99_latency_ms_max"],
            },
        }

        all_passed = all(details["passed"] for details in criteria_details.values())

        logger.info(
            "launch_criteria_check",
            criteria_details=criteria_details,
            all_passed=all_passed,
        )

        return all_passed, criteria_details

    def _calculate_readiness_score(
        self,
        signal_quality: SignalQualityMetrics,
        execution_efficiency: ExecutionEfficiencyMetrics,
        pnl_attribution: PnLAttribution,
        uptime_pct: float,
    ) -> float:
        """è®¡ç®—å‡†å¤‡åº¦è¯„åˆ†ï¼ˆ0-100ï¼‰

        è¯„åˆ†è§„åˆ™ï¼š
            - IC è¯„åˆ†ï¼š0-25 åˆ†ï¼ˆIC >= 0.05 æ»¡åˆ†ï¼‰
            - Alpha å æ¯”è¯„åˆ†ï¼š0-25 åˆ†ï¼ˆAlpha >= 100% æ»¡åˆ†ï¼‰
            - å»¶è¿Ÿè¯„åˆ†ï¼š0-25 åˆ†ï¼ˆp99 <= 100ms æ»¡åˆ†ï¼‰
            - ç¨³å®šæ€§è¯„åˆ†ï¼š0-25 åˆ†ï¼ˆåœ¨çº¿ç‡ 100% æ»¡åˆ†ï¼‰
        """
        scores = []

        # IC è¯„åˆ†ï¼ˆ0-25 åˆ†ï¼‰ï¼Œç¡®ä¿éè´Ÿ
        ic_score = max(0, min(signal_quality.ic / 0.05 * 25, 25))
        scores.append(ic_score)

        # Alpha å æ¯”è¯„åˆ†ï¼ˆ0-25 åˆ†ï¼‰ï¼Œç¡®ä¿éè´Ÿ
        alpha_score = max(0, min(pnl_attribution.alpha_percentage / 100 * 25, 25))
        scores.append(alpha_score)

        # å»¶è¿Ÿè¯„åˆ†ï¼ˆ0-25 åˆ†ï¼‰ï¼Œç¡®ä¿éè´Ÿ
        latency_score = max(
            0, min(25 - (execution_efficiency.p99_total_latency_ms - 100) / 10, 25)
        )
        scores.append(latency_score)

        # ç¨³å®šæ€§è¯„åˆ†ï¼ˆ0-25 åˆ†ï¼‰ï¼Œç¡®ä¿éè´Ÿ
        uptime_score = max(0, min(uptime_pct / 100 * 25, 25))
        scores.append(uptime_score)

        return sum(scores)
